{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Data generator class\n",
    "class ImageDataGeneratorWithLabels(tf.keras.utils.Sequence):\n",
    "    def __init__(self, gray_folder_path, color_folder_path, batch_size=24, img_size=(256, 256)):\n",
    "        self.gray_folder_path = gray_folder_path\n",
    "        self.color_folder_path = color_folder_path\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.gray_images = os.listdir(gray_folder_path)\n",
    "        self.color_images = os.listdir(color_folder_path)\n",
    "\n",
    "        # Augmentation for data\n",
    "        self.augmentation = ImageDataGenerator(\n",
    "            rotation_range=30,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.gray_images) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_gray = self.gray_images[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_color = self.color_images[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "\n",
    "        for gray_img, color_img in zip(batch_gray, batch_color):\n",
    "            gray_path = os.path.join(self.gray_folder_path, gray_img)\n",
    "            color_path = os.path.join(self.color_folder_path, color_img)\n",
    "\n",
    "            # Load and preprocess grayscale image\n",
    "            img_gray = load_img(gray_path, target_size=self.img_size)\n",
    "            img_gray = img_to_array(img_gray) / 255\n",
    "            X_batch.append(np.stack((img_gray[:, :, 0],) * 3, axis=-1))  # Convert grayscale to RGB\n",
    "\n",
    "            # Load and preprocess color image\n",
    "            img_color = load_img(color_path, target_size=self.img_size)\n",
    "            img_color = img_to_array(img_color) / 255\n",
    "            lab_image = rgb2lab(img_color)\n",
    "            lab_image_norm = (lab_image + [0, 128, 128]) / [100, 255, 255]\n",
    "            Y_batch.append(lab_image_norm[:, :, 1:])  # Keep only AB channels\n",
    "\n",
    "        # Apply augmentation\n",
    "        X_batch = np.array(X_batch, dtype=np.float32)\n",
    "        Y_batch = np.array(Y_batch, dtype=np.float32)\n",
    "\n",
    "        # Using the ImageDataGenerator for augmentation\n",
    "        augmented_X_batch = self.augmentation.flow(X_batch, batch_size=self.batch_size, shuffle=False).next()\n",
    "\n",
    "        return augmented_X_batch, Y_batch\n",
    "\n",
    "# Paths to folders containing images\n",
    "gray_folder_path = './ColorizationImages/gray/'\n",
    "color_folder_path = './ColorizationImages/color/'\n",
    "\n",
    "# Initialize data generators for training and validation\n",
    "train_data_gen = ImageDataGeneratorWithLabels(gray_folder_path, color_folder_path, batch_size=24)\n",
    "val_data_gen = ImageDataGeneratorWithLabels(gray_folder_path, color_folder_path, batch_size=24)  # Replace with actual validation paths\n",
    "\n",
    "# Function to get latest epoch from checkpoint files\n",
    "def get_latest_epoch(checkpoint_dir):\n",
    "    files = os.listdir(checkpoint_dir)\n",
    "    epoch_files = [f for f in files if re.search(r'model_epoch_(\\d+).keras', f)]\n",
    "    if not epoch_files:\n",
    "        return None, None\n",
    "    latest_file = max(epoch_files, key=lambda f: int(re.search(r'(\\d+)', f).group()))\n",
    "    latest_epoch = int(re.search(r'(\\d+)', latest_file).group())\n",
    "    return latest_file, latest_epoch\n",
    "\n",
    "# Load VGG16 model without fully connected layers\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze VGG16 layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the model\n",
    "x = vgg.output\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Output: (16, 16, 512)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Output: (32, 32, 256)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Output: (64, 64, 128)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Output: (128, 128, 64)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Output: (256, 256, 32)\n",
    "\n",
    "# Final output layer with 2 channels (AB)\n",
    "output_layer = Conv2D(2, (3, 3), activation='sigmoid', padding='same')(x)  # (256, 256, 2)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=vgg.input, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='mse')\n",
    "\n",
    "# Check for existing checkpoints and load the latest one\n",
    "checkpoint_dir = './checkpoints/'\n",
    "latest_file, latest_epoch = get_latest_epoch(checkpoint_dir)\n",
    "\n",
    "if latest_file:\n",
    "    print(f\"Loading model from checkpoint: {latest_file}\")\n",
    "    model.load_weights(os.path.join(checkpoint_dir, latest_file))\n",
    "else:\n",
    "    print(\"No checkpoints found, starting training from scratch.\")\n",
    "    latest_epoch = 0\n",
    "\n",
    "# Set up early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define checkpoint callback to save the model at each epoch\n",
    "checkpoint_filepath = './checkpoints/model_epoch_{epoch:02d}.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath, \n",
    "    save_best_only=False,  # Set to True to only save the best model based on val_loss\n",
    "    save_weights_only=False,  # Save the entire model, not just the weights\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    verbose=1  # Display message when saving model\n",
    ")\n",
    "\n",
    "# Train the model and save checkpoints\n",
    "model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=latest_epoch + 100,  # Continue training from latest epoch\n",
    "    initial_epoch=latest_epoch,\n",
    "    callbacks=[early_stopping, model_checkpoint],  # Add model checkpoint to callbacks\n",
    "    validation_data=val_data_gen  # You should replace this with a separate validation generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.color import lab2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from skimage.transform import resize  # Import resize for better quality\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('./checkpoints/model_epoch_06.keras')  # Adjust the path and file name as necessary\n",
    "\n",
    "# Testing the model with a higher resolution image\n",
    "folder_path = './ColorizationImages/gray/'\n",
    "img_name = 'image_605.jpg'\n",
    "img_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "# Load and preprocess grayscale image with the required resolution\n",
    "img = load_img(img_path, target_size=(256, 256), color_mode=\"grayscale\")  # Change target size to 256x256\n",
    "img = img_to_array(img) / 255.0  # Scale to [0, 1]\n",
    "\n",
    "# Convert grayscale image to a 3-channel image by repeating the single channel\n",
    "img_rgb = np.stack((img[:, :, 0],) * 3, axis=-1)  # Create RGB image from grayscale\n",
    "X_test = np.expand_dims(img_rgb, axis=0)  # Add batch dimension, resulting in shape (1, 256, 256, 3)\n",
    "\n",
    "# Predict and reshape the output\n",
    "output = model.predict(X_test)\n",
    "output = np.reshape(output, (256, 256, 2))  # Resize to (256, 256, 2)\n",
    "\n",
    "# Create the LAB image with the correct scaling\n",
    "outputLAB = np.zeros((256, 256, 3))\n",
    "outputLAB[:, :, 0] = img[:, :, 0] * 100  # L channel, scaled to [0, 100]\n",
    "outputLAB[:, :, 1:] = output * 255 - 128  # AB channels, scaled to [-128, 127]\n",
    "\n",
    "# Convert LAB image back to RGB\n",
    "rgb_image = lab2rgb(outputLAB)\n",
    "\n",
    "# Resize the final RGB image to 256x256 for better quality display\n",
    "rgb_image_resized = resize(rgb_image, (256, 256), anti_aliasing=True)\n",
    "\n",
    "# Show the output image\n",
    "plt.imshow(rgb_image_resized)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
